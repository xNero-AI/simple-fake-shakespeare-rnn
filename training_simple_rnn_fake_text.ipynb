{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LET'S DO THISS!!! :DDDD\n"
     ]
    }
   ],
   "source": [
    "# Lets check your GPU\n",
    "if tf.config.list_logical_devices('GPU') != []:\n",
    "    print(\"LET'S DO THISS!!! :DDDD\")\n",
    "else: \n",
    "    print(\"Oh dude... D:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/input.txt') as f:\n",
    "    content = f.read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first citizen:\n",
      "before we proceed any further, hear me speak.\n",
      "\n",
      "all:\n",
      "speak, speak.\n",
      "\n",
      "first citizen:\n",
      "you\n"
     ]
    }
   ],
   "source": [
    "print(content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"\\n !$&',-.3:;?abcdefghijklmnopqrstuvwxyz\",\n",
       " \"\\n !$&',-.3:;?abcdefghijklmnopqrstuvwxyz<PAD><UNK>\")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_characters = sorted(set(content.lower()))\n",
    "all_tokens = all_characters + ['<PAD>', '<UNK>']\n",
    "\"\".join(all_characters), \"\".join(all_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "\n",
    "Lets preprocess data. The key idea is cut all data in windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1109478,  305053,  374053,   43191,  132750,  947160,  196038,\n",
       "         793705,  184852,  765738]),\n",
       " 200000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "input_data_size = 128\n",
    "window_size = input_data_size + 1\n",
    "n_total_char = len(content)\n",
    "n_total_tokens = len(all_tokens)\n",
    "\n",
    "start_window_list = range(0, n_total_char - window_size)\n",
    "\n",
    "start_window_list = np.random.choice(start_window_list, size=200_000, replace=False)\n",
    "\n",
    "start_window_list[:10], len(start_window_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create encoder\n",
    "char_to_index = {char: index for index, char in enumerate(all_tokens)}\n",
    "\n",
    "# Create decoder\n",
    "index_to_char = np.array(all_tokens)\n",
    "\n",
    "def encode(text):\n",
    "    return np.array([char_to_index.get(char, char_to_index['<UNK>']) for char in text])\n",
    "\n",
    "def decode(vector):\n",
    "    return \"\".join(index_to_char[vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['ses too.\\n\\nantonio:\\nwhat impossible matter will he make easy next?\\n\\nsebastian:\\ni think he will carry this island home in his pock',\n",
       "        'e'],\n",
       "       [' will not sup to-night.\\ngive me some ink and paper.\\nwhat, is my beaver easier than it was?\\nand all my armour laid into my tent?\\n',\n",
       "        '\\n'],\n",
       "       ['ds confess,\\nbecause my power is weak and all ill left:\\nbut if i could, by him that gave me life,\\ni would attach you all and make',\n",
       "        ' '],\n",
       "       [\"n.\\n\\nvolumnia:\\ni know not where to turn: o, welcome home:\\nand welcome, general: and ye're welcome all.\\n\\nmenenius:\\na hundred thous\",\n",
       "        'a'],\n",
       "       [\" here's\\nwater to quench it. i was hardly moved to come to\\nthee; but being assured none but myself could move\\nthee, i have been b\",\n",
       "        'l'],\n",
       "       ['terly remorse confutes mine honour,\\nand i did yield to him: but the next morn betimes,\\nhis purpose surfeiting, he sends a warran',\n",
       "        't'],\n",
       "       [\":\\n'zounds, he dies: i had forgot the reward.\\n\\nfirst murderer:\\nwhere is thy conscience now?\\n\\nsecond murderer:\\nin the duke of glou\",\n",
       "        'c'],\n",
       "       [\"nk you?\\n\\nautolycus:\\nvery true, and but a month old.\\n\\ndorcas:\\nbless me from marrying a usurer!\\n\\nautolycus:\\nhere's the midwife's n\",\n",
       "        'a'],\n",
       "       [\"cester:\\ni cry thee mercy then, for i had thought\\nthat thou hadst call'd me all these bitter names.\\n\\nqueen margaret:\\nwhy, so i di\",\n",
       "        'd'],\n",
       "       ['ded you\\nof what you should forget. now, good my liege\\nsir, royal sir, forgive a foolish woman:\\nthe love i bore your queen--lo, f',\n",
       "        'o']], dtype='<U128')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windows_list = np.array([(content[i:i+window_size - 1], content[i+window_size - 1:i+window_size]) for i in start_window_list])\n",
    "windows_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "for x in windows_list:\n",
    "    X.append(encode(x[0]))\n",
    "    y.append(encode(x[1]))\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "n_all_char = len(all_characters)\n",
    "\n",
    "X = X\n",
    "y = y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000, 128)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000, 128, 1)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:, :, np.newaxis].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_stack = keras.Sequential([\n",
    "    keras.layers.Embedding(input_dim=n_all_char, output_dim=16),\n",
    "    keras.layers.GRU(128),\n",
    "])\n",
    "\n",
    "dense_stack = keras.Sequential([\n",
    "    keras.layers.Dense(n_all_char, activation='softmax')\n",
    "])\n",
    "\n",
    "model = keras.Sequential([\n",
    "    rnn_stack,\n",
    "    dense_stack\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 128, 1)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10][:, :, np.newaxis].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 39), dtype=float32, numpy=\n",
       "array([[0.02574085, 0.02552984, 0.02565905, 0.02564526, 0.02569479,\n",
       "        0.02558819, 0.02570878, 0.02578306, 0.02558905, 0.02572094,\n",
       "        0.02578873, 0.02553393, 0.02550666, 0.02573321, 0.02552141,\n",
       "        0.02565779, 0.02545676, 0.0254726 , 0.02564199, 0.02562056,\n",
       "        0.02565015, 0.02534459, 0.02587151, 0.02567762, 0.02543338,\n",
       "        0.02578236, 0.02561135, 0.02567596, 0.0255293 , 0.02597448,\n",
       "        0.02584625, 0.02576393, 0.02570429, 0.02537828, 0.02557098,\n",
       "        0.02555002, 0.02555855, 0.0258151 , 0.0256684 ],\n",
       "       [0.02557015, 0.02556382, 0.0258853 , 0.02547315, 0.02572223,\n",
       "        0.02554747, 0.02560454, 0.02581258, 0.02542062, 0.02568618,\n",
       "        0.0255821 , 0.02575505, 0.02557503, 0.02544116, 0.02553587,\n",
       "        0.02563226, 0.02572292, 0.02530951, 0.02562159, 0.0256429 ,\n",
       "        0.02536375, 0.02561276, 0.02573848, 0.02566213, 0.0255566 ,\n",
       "        0.02573719, 0.02575745, 0.02595556, 0.02578335, 0.02610767,\n",
       "        0.0255233 , 0.02554207, 0.02567303, 0.02568197, 0.02559349,\n",
       "        0.02570033, 0.02542247, 0.02587112, 0.02561284],\n",
       "       [0.02574836, 0.02554755, 0.02578357, 0.02554918, 0.02574594,\n",
       "        0.0257146 , 0.02547429, 0.02567803, 0.02553757, 0.02562979,\n",
       "        0.025544  , 0.02563213, 0.02565652, 0.02549319, 0.02567134,\n",
       "        0.02560888, 0.02559316, 0.02551266, 0.02563862, 0.02573347,\n",
       "        0.02562322, 0.02561254, 0.02568529, 0.02575909, 0.02563182,\n",
       "        0.02554012, 0.02555007, 0.02569138, 0.02555508, 0.02563485,\n",
       "        0.02570043, 0.02566812, 0.02574295, 0.02569888, 0.02564547,\n",
       "        0.02574442, 0.02556315, 0.0257526 , 0.02570767],\n",
       "       [0.02553813, 0.02576446, 0.02543167, 0.02559909, 0.02541479,\n",
       "        0.02585264, 0.02559916, 0.02566493, 0.02547211, 0.02569013,\n",
       "        0.02569455, 0.02567505, 0.02555886, 0.02572248, 0.02582004,\n",
       "        0.02572638, 0.02554318, 0.0256658 , 0.02561854, 0.02552091,\n",
       "        0.02578585, 0.02566213, 0.02585876, 0.02549532, 0.02567743,\n",
       "        0.02556171, 0.02585217, 0.02584245, 0.02568181, 0.02555611,\n",
       "        0.02567045, 0.02557095, 0.02539044, 0.02570155, 0.02545174,\n",
       "        0.02574172, 0.02559284, 0.02559438, 0.02573933],\n",
       "       [0.02561511, 0.02558305, 0.02578003, 0.02560836, 0.02548753,\n",
       "        0.02559654, 0.02563565, 0.02572808, 0.02569659, 0.02577926,\n",
       "        0.02553362, 0.02555499, 0.02563163, 0.02545505, 0.0256835 ,\n",
       "        0.02581325, 0.02570334, 0.02536576, 0.02550787, 0.02564539,\n",
       "        0.02552331, 0.02548831, 0.0258516 , 0.02581888, 0.02545291,\n",
       "        0.02567981, 0.025747  , 0.02590866, 0.0257117 , 0.02616803,\n",
       "        0.02559843, 0.02553139, 0.02552686, 0.02558673, 0.02553862,\n",
       "        0.02566303, 0.02537657, 0.0256772 , 0.02574641],\n",
       "       [0.02546248, 0.02569444, 0.02562275, 0.02554497, 0.02576254,\n",
       "        0.02562401, 0.02567645, 0.02554868, 0.0258145 , 0.02562542,\n",
       "        0.0255937 , 0.02554632, 0.0257539 , 0.0256497 , 0.0257169 ,\n",
       "        0.02563956, 0.02563977, 0.02568023, 0.02571538, 0.0256223 ,\n",
       "        0.02553322, 0.02591059, 0.02558472, 0.02557546, 0.02563609,\n",
       "        0.02559169, 0.02554564, 0.02541897, 0.02573918, 0.02546947,\n",
       "        0.02555411, 0.02572363, 0.02585639, 0.0258399 , 0.02577741,\n",
       "        0.02565055, 0.02561432, 0.02557958, 0.02546507],\n",
       "       [0.02534387, 0.02568277, 0.02535612, 0.02567635, 0.02543179,\n",
       "        0.02568178, 0.02561534, 0.02591697, 0.02537327, 0.0256132 ,\n",
       "        0.02572391, 0.02566962, 0.02560576, 0.0258    , 0.0258367 ,\n",
       "        0.02586449, 0.02551644, 0.02566556, 0.02577801, 0.02556442,\n",
       "        0.0257706 , 0.02570607, 0.02580338, 0.0255087 , 0.02553661,\n",
       "        0.02561382, 0.02595404, 0.02590225, 0.02571082, 0.02557098,\n",
       "        0.02577051, 0.02560871, 0.02527493, 0.025475  , 0.02523701,\n",
       "        0.02589603, 0.02565949, 0.02549929, 0.02578539],\n",
       "       [0.02556736, 0.02552363, 0.02568135, 0.02550496, 0.0257996 ,\n",
       "        0.02550866, 0.02566278, 0.02589416, 0.02564232, 0.02562953,\n",
       "        0.02570371, 0.02568426, 0.02568811, 0.02557586, 0.02547172,\n",
       "        0.02569211, 0.0257039 , 0.02541417, 0.0258331 , 0.02545377,\n",
       "        0.02549188, 0.02573567, 0.02567369, 0.02573183, 0.02551166,\n",
       "        0.02578091, 0.02566361, 0.02566345, 0.02572103, 0.02581815,\n",
       "        0.02551381, 0.02557403, 0.02578317, 0.02556288, 0.02548865,\n",
       "        0.02570638, 0.02560095, 0.02572697, 0.02561622],\n",
       "       [0.02574497, 0.02560204, 0.02538676, 0.02569314, 0.02553375,\n",
       "        0.02572512, 0.02577515, 0.02561485, 0.0254657 , 0.02570246,\n",
       "        0.02576067, 0.02572592, 0.02563942, 0.0258598 , 0.02536405,\n",
       "        0.02557451, 0.02565793, 0.02553614, 0.02566125, 0.02568857,\n",
       "        0.02577489, 0.02545039, 0.02558539, 0.02584356, 0.02566265,\n",
       "        0.02582008, 0.02577762, 0.02568934, 0.02557391, 0.02567472,\n",
       "        0.02572932, 0.02555965, 0.02562338, 0.02540066, 0.02545089,\n",
       "        0.02570548, 0.0256554 , 0.02564172, 0.02566871],\n",
       "       [0.02569367, 0.02565845, 0.02558378, 0.02549928, 0.0255141 ,\n",
       "        0.0257664 , 0.02564306, 0.0257095 , 0.02568899, 0.02577728,\n",
       "        0.02571202, 0.02575228, 0.02558353, 0.0255552 , 0.02559388,\n",
       "        0.02561415, 0.02562163, 0.02546182, 0.02570982, 0.02539828,\n",
       "        0.0256978 , 0.02581304, 0.02592152, 0.02569222, 0.02561342,\n",
       "        0.02561667, 0.0256993 , 0.02574592, 0.02575653, 0.02580113,\n",
       "        0.02551871, 0.0254268 , 0.02579726, 0.02561747, 0.02575113,\n",
       "        0.02562281, 0.02548472, 0.02558846, 0.02529797]], dtype=float32)>"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_stack(rnn_stack(X_train[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='nadam', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_65 (Sequential)  (None, 128)               56688     \n",
      "                                                                 \n",
      " sequential_66 (Sequential)  (None, 39)                5031      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,719\n",
      "Trainable params: 61,719\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 101s 25ms/step - loss: 2.3244 - accuracy: 0.3262 - val_loss: 2.0600 - val_accuracy: 0.3938\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 136s 34ms/step - loss: 1.9636 - accuracy: 0.4196 - val_loss: 1.8830 - val_accuracy: 0.4427\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 140s 35ms/step - loss: 1.8084 - accuracy: 0.4627 - val_loss: 1.7865 - val_accuracy: 0.4700\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 121s 30ms/step - loss: 1.7111 - accuracy: 0.4876 - val_loss: 1.7407 - val_accuracy: 0.4819\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 86s 22ms/step - loss: 1.6424 - accuracy: 0.5051 - val_loss: 1.7065 - val_accuracy: 0.4915\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 102s 26ms/step - loss: 1.5928 - accuracy: 0.5172 - val_loss: 1.6850 - val_accuracy: 0.5007\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 92s 23ms/step - loss: 1.5520 - accuracy: 0.5293 - val_loss: 1.6706 - val_accuracy: 0.5023\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 94s 23ms/step - loss: 1.5180 - accuracy: 0.5371 - val_loss: 1.6729 - val_accuracy: 0.5013\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 96s 24ms/step - loss: 1.4902 - accuracy: 0.5445 - val_loss: 1.6699 - val_accuracy: 0.5034\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 98s 24ms/step - loss: 1.4665 - accuracy: 0.5512 - val_loss: 1.6618 - val_accuracy: 0.5100\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fake text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pretrained_model = True\n",
    "\n",
    "if get_pretrained_model:\n",
    "    model = keras.models.load_model('Saved Models/model_shakespeare.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('to be or not ', 't')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "input_text = 'to be or not '\n",
    "encoded_text = encode(input_text)\n",
    "prediction = model.predict(encoded_text[np.newaxis, :], verbose=0)\n",
    "decode(encoded_text), decode(np.argmax(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to be or not too\n",
      "\n",
      "king richard iii:\n",
      "and the pater to the patient that the markent here in his consent\n",
      "of the patient that the marker and her "
     ]
    }
   ],
   "source": [
    "input_text = 'to be or not '\n",
    "encoded_text = encode(input_text)\n",
    "print(input_text, end='', flush=True)\n",
    "for i in range(128):\n",
    "    \n",
    "    prediction = model.predict(encoded_text[np.newaxis, :], verbose=0)\n",
    "    encoded_text = np.append(encoded_text, np.argmax(prediction))\n",
    "    decoded_text = decode(encoded_text)\n",
    "    print(decoded_text[-1], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('Saved Models/model_shakespeare.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
