{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LET'S DO THISS!!! :DDDD\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Lets check your GPU\n",
    "if tf.config.list_logical_devices('GPU') != []:\n",
    "    print(\"LET'S DO THISS!!! :DDDD\")\n",
    "else: \n",
    "    print(\"Oh dude... D:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first citizen:\n",
      "before we proceed any further, hear me speak.\n",
      "\n",
      "all:\n",
      "speak, speak.\n",
      "\n",
      "first citizen:\n",
      "you\n"
     ]
    }
   ],
   "source": [
    "with open('data/input.txt') as f:\n",
    "    content = f.read().lower()\n",
    "    \n",
    "print(content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n !$&',-.3:;?abcdefghijklmnopqrstuvwxyz\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(sorted(set(content.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vec_layer = keras.layers.TextVectorization(\n",
    "                                                split=\"character\",\n",
    "                                                standardize=\"lower\"\n",
    "                                            )\n",
    "text_vec_layer.adapt([content])\n",
    "encoded = text_vec_layer([content])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded -= 2  # drop tokens 0 (pad) and 1 (unknown), subtraindo 2 (pad e unknown)\n",
    "n_tokens = text_vec_layer.vocabulary_size() - 2  # number of distinct chars = 39\n",
    "dataset_size = len(encoded)  # total number of chars = 1,115,394"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 1115394)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tokens, dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 128\n",
    "batch_size = 32\n",
    "ds = tf.data.Dataset.from_tensor_slices(encoded) # Fatia o ds em janelas de tamanho window_size\n",
    "ds = ds.window(window_size + 1, shift=1, drop_remainder=True) # Você pode visualizar com um .as_numpy_iterator() e colocar num loop com .take(1)\n",
    "ds = ds.flat_map(lambda window: window.batch(window_size + 1)) # Transforma cada janela em um tensor\n",
    "ds = ds.shuffle(100_000, seed=42)\n",
    "ds = ds.batch(batch_size)\n",
    "ds = ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128) (32, 128)\n",
      "tf.Tensor(\n",
      "[15  0  9  3 16 17  0  9  3  0 14  3  8  1 26 10 10 18  3 14  5  9  5 13\n",
      "  7 23 10 11  3  3 24 17  0  7  5  8 17  0 15  3 13  8  0 14  3  2  6  1\n",
      "  8 30 10 10 18  3  8  5  3 11  4  9 13  7 23 10  3 17 10 15  3 13  0  6\n",
      "  4 25  1 17  0  5  0 24  9  3 16 17  0 22  1  2  5  2  5  3  9 27 12  0\n",
      "  4 11 11  0  2  6  1  0 20  3 12  7 10 19  3  8  0 14 15  0 22  8  3  7\n",
      " 22  1  8  5  2 15 30 10], shape=(128,), dtype=int64) tf.Tensor(\n",
      "[ 0  9  3 16 17  0  9  3  0 14  3  8  1 26 10 10 18  3 14  5  9  5 13  7\n",
      " 23 10 11  3  3 24 17  0  7  5  8 17  0 15  3 13  8  0 14  3  2  6  1  8\n",
      " 30 10 10 18  3  8  5  3 11  4  9 13  7 23 10  3 17 10 15  3 13  0  6  4\n",
      " 25  1 17  0  5  0 24  9  3 16 17  0 22  1  2  5  2  5  3  9 27 12  0  4\n",
      " 11 11  0  2  6  1  0 20  3 12  7 10 19  3  8  0 14 15  0 22  8  3  7 22\n",
      "  1  8  5  2 15 30 10 10], shape=(128,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in ds.take(1):\n",
    "    print(X_batch.shape, y_batch.shape)\n",
    "    print(X_batch[0], y_batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando função\n",
    "def to_dataset(sequence, window_size=128, batch_size=32, seed=42, shuffle=False, target='all_window'):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(sequence) # Fatia o ds em janelas de tamanho window_size\n",
    "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True) # Você pode visualizar com um .as_numpy_iterator() e colocar num loop com .take(1)\n",
    "    ds = ds.flat_map(lambda window: window.batch(window_size + 1)) # Transforma cada janela em um tensor\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(100_000, seed=seed)\n",
    "    ds = ds.batch(batch_size)\n",
    "    if target == 'all_window':\n",
    "        ds = ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)\n",
    "    elif target == 'last_char':\n",
    "        ds = ds.map(lambda window: (window[:, :-1], window[:, -1])).prefetch(1)\n",
    "    else:\n",
    "        raise ValueError('target must be \"all_window\" or \"last_char\"')\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n",
       "  array([[ 4,  5,  2],\n",
       "         [ 5,  2, 23]], dtype=int64)>,\n",
       "  <tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n",
       "  array([[ 5,  2, 23],\n",
       "         [ 2, 23,  3]], dtype=int64)>)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo de uso\n",
    "list(to_dataset(text_vec_layer(['To be'])[0], window_size=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 128\n",
    "tf.random.set_seed(42)\n",
    "train_set = to_dataset(encoded[:1_000_000], window_size=window_size, shuffle=True, seed=42)\n",
    "valid_set = to_dataset(encoded[1_000_000:1_060_000], window_size=window_size)\n",
    "test_set = to_dataset(encoded[1_060_000:], window_size=window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Char-RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # extra code – ensures reproducibility on CPU\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True),\n",
    "    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(seq, delta=2):\n",
    "    output = np.array(text_vec_layer.get_vocabulary())[seq + delta]\n",
    "    new_output = []\n",
    "    for i in range(output.shape[0]):\n",
    "        phrase = \"\"\n",
    "        for j in range(output.shape[1]):\n",
    "            phrase += output[i, j]\n",
    "        new_output.append(phrase)\n",
    "    return np.array(new_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estilo\n",
    "plt.style.use('dark_background')\n",
    "plt.rcParams['axes.facecolor'] = '#26262e' \n",
    "\n",
    "def print_multiple_generated(predicted_text, original_text, n=8):\n",
    "    print(\"--> Original text:\")\n",
    "    for i in range(n):\n",
    "        print(original_text[i])\n",
    "    print(\"\\n--> Generated text:\")\n",
    "    for i in range(n):\n",
    "        print(predicted_text[i])\n",
    "        \n",
    "def plot_loss(history, step):\n",
    "    plt.plot(list(range(len(history['loss']))), history['loss'], label='Training Loss')\n",
    "    plt.plot(list(range(len(history['loss']))), history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_accuracy(history, step):\n",
    "    plt.plot(list(range(len(history['accuracy']))), history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(list(range(len(history['accuracy']))), history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {\n",
    "            'text_base': 'To be or not to be, that is the question:',\n",
    "            'text_base_encoded': text_vec_layer(['To be or not to be, that is the question:']),\n",
    "            'list_predicted_text_base': [],\n",
    "        }\n",
    "\n",
    "class LogCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, history):\n",
    "        super().__init__()\n",
    "        self.history_ = history\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"Final da época {epoch}, Loss: {logs['loss']}, Acc: {logs['accuracy']}\")\n",
    "    \n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        if batch % 3_000 == 0:\n",
    "            print(\"\")\n",
    "            print(f\"Final do lote {batch}, Loss do lote: {logs['loss']}\")\n",
    "            model = self.model\n",
    "            predicted_text = decoder(tf.argmax(model(history['text_base_encoded'], training=False), axis=2))[0]\n",
    "            print(\"\")\n",
    "            print(\"--> Original text: \", history['text_base'])\n",
    "            print(\"--> Generated text: \", predicted_text)\n",
    "            self.history_['list_predicted_text_base'].append(predicted_text)\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"my_shakespeare_model\", monitor=\"val_accuracy\", save_best_only=True)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "              optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\n",
      "Final do lote 0, Loss do lote: 3.6630570888519287\n",
      "\n",
      "--> Original text:  To be or not to be, that is the question:\n",
      "--> Generated text:  e   n            nf  e   n   ee      d   \n",
      "\n",
      "   1408/Unknown - 35s 16ms/step - loss: 2.0736 - accuracy: 0.3985"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history_train \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mLogCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mmodel_ckpt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\toydl\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\toydl\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\toydl\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\toydl\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\toydl\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\toydl\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\toydl\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\toydl\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\toydl\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history_train = model.fit(train_set, \n",
    "                    validation_data=valid_set, \n",
    "                    epochs=10,\n",
    "                    callbacks=[LogCallback(history=history), \n",
    "                               model_ckpt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['i e t poman  tor y cannot \\nte ng o melsce,\\nae nhet i am \\nconsition.\\n\\nhat io d momfition oap tssraat .sord tn the pert thet h  t ',\n",
       "        'eo  d tirrs ahe corinint hnes the gomntenlowdgiart  wha cnm tfr btldier, nur seaed toe coat\\nwhe crwguesmfr rritpetsr.\\n\\nhth auher',\n",
       "        'e nn:aomber,\\ntheu h thet s th t l  tyst i dheedt trom tul  tha cest whall be t the cutiness,in tome tther trrht \\nwn chrse till h',\n",
       "        'en and ti lome  ioneral  tnd toare wallome.onl \\n\\nmenenius:\\nw gamgred iheu and tilcome ,\\ni aauld ni p,t d tnsauld birgh  t am hog',\n",
       "        \"uehres to tine yss restrnetion, ai pe maght we canl'd your voltuisher.\\n\\ncoriolanus:\\nwy an ium tifes hea\\n\\ncartius:\\nt  antium \\n\\nco\",\n",
       "        's:\\nt ll nnep youraomeany \\nietl you arlne \\n\\ncrutus:\\nwh hhan tere tor the people,\\n\\ncicinius:\\ntore you tell.\\nhe has at iot, snd te ',\n",
       "        'tthe common  tou sholl bond yotmutlichaenemit teach tou tepeive\\ntut tt iroveeds tf womis toom the  to tourtnd to miy soom tourse',\n",
       "        'hte nt wo the pods,\\naast i dhan he t to the .\\n\\ncilumnia:\\niou are to  rloolute \\nahaugh the efn you aon tover se sh  robles\\naut ti',\n",
       "        'eyuoude \\ntnd thlt them elves tith teath.\\nwf tll the conses  whine f ye have boken tood fnd tiod corre-\\nar tll the criadore tn th',\n",
       "        'eye  tn the pors toorgh srd.\\n\\nmoriolanus:\\nwhaothhes mith teoefs, wiars th mare taughter of y \\n\\ncenenius:\\nwomsider torther \\nthat ',\n",
       "        ' t tilh ut ais trie fotpeantng \\n\\nborgilia:\\nihe gods soavt them toue \\n\\nvolumnia:\\nihue, irle mhr  \\ncenenius:\\nihue, i ll be soorn t',\n",
       "        'utlete tower  w say, they hotrdsh d tissdecienced wol the codn,af the ptate,\\n\\nsrutus:\\nwhy, hiall bhe ceople arvenhne that hheak ',\n",
       "        'riie   timh rt \\nta, iorewell.\\n\\nsartius:\\ntheu airthyort marcius,\\n\\no, si,nd the caitpetstn the panket-place.\\nwall thesher tnl the ',\n",
       "        \"tosth,tnt ernnt besiaike and chet ses country's sear dsahan ais.elf  wet tim tuone, wr wo mar. atnsandsd,\\nwhre thes  ih txcress \",\n",
       "        'ngus:\\nth haange tour thet iou have bonteyved th thke\\narom tome all terton,d hf icerand th pind your elf tn o t power,tooennical ',\n",
       "        'e tor h aut that ie hays tisself aith trlng aromd.\\n\\nmicond citizen:\\nwoy, mut tieak tot taricious y \\n\\ncirst sitizen:\\nw way tpto y',\n",
       "        ' e ure: ae eech you, i say se consul,\\n\\ncirsh citizen:\\nye hame th tind yourtfr oriends\\nand the e ore,hove you tfr foices,ae rtsly',\n",
       "        'he airk tou, tre ton ot boll yiu to tay thet \\ntor the peaende,of tndown  irr general is avcellent \\n\\ncirst servingman:\\nwn, tnd to',\n",
       "        \" aoth trnd af senvsand cea  te n tuk. aith tolhes, tevg io' douet yot\\n\\nhth aver  meneti tourto toange tscandl wnd tonl tim totle\",\n",
       "        'e won ot toufeudertet oy the goarand tobff teneral isnorance, -it mast bfdnhoead towkssioios  and tove hay,toa caoce\\nto msdearle',\n",
       "        'ore trle \\nih tlpoael tes i sent tim  boom thence ai heturn d,\\nwes crows tyynd tith tnk. i holl thee, toyghter, ansaeengeiot sore',\n",
       "        ' rtter:\\nto,le ssfidius,\\nthke tour sonmossion  ies tou th tour venis, het ts gllne,to tierd touioli \\nit ihey hae town tefore ht \\n',\n",
       "        'tored the ceople \\n\\ncirst sitizen:\\nwe s tne tolost mndugh  thuld trl the coct iire ht \\n\\ncenenius:\\nihat wiuk d  ay lountry en  tn ',\n",
       "        't hancit hnei ng hes pobllity.\\nand ti e tnhm  theng,het oiat isam. t would hith hy fn y ti \\n\\ncorinius:\\nwou save bought to ether.',\n",
       "        ' \\nte dash secisted tiyi\\nand the e ore heyshholl beorn aim turther.thibl\\nihan the cenertty sf the petlichaower tiach te ih sut \\na',\n",
       "        \"et s t srace hollow, aut te s dergeance oroud  and tines iot the cimmon meople,\\n\\ncicond cfficer:\\ntarth  ihe e'ias deen myny araa\",\n",
       "        'toople,aenneth the e serd thubunes,\\n\\n  thal wopendeng  ahanr vwedience soir  th the poeat r teaihe hn a revellyon. whon heat s t',\n",
       "        'hth suesch \\n\\nvirst serator:\\nth tsdurnd the coty,ind th tar tsl tratt\\n\\nvicinius:\\nthat is the coty iut the ceople,\\n\\ncotizens:\\nihue',\n",
       "        \"nsl bave bou thkk d mith t on \\n\\nchird cervingman:\\nwhat ioalow,s shen \\n\\ncirst servingman:\\nwnmoaange one tn aver t cooked tn  i'aa\",\n",
       "        'tenenius:\\nwhet s tirthyee as tn  txr tor te r  iome, cet s hot oirp.\\n\\n  ithauld beoke af iort one oonentyoars,toom the e snd hrm',\n",
       "        '  tonsurnd an hour \\nand tuing the naws bo site \\n\\ncensenger:\\ntoers of the pilsces ae p he nn hoare, ahet t ais aor e  th hienl th',\n",
       "        'ni iheygintert trme to trniept t san s aite an then the s gaclen aft oith hir hasband,\\niou  veble lhmlus aufidius till onpear.ii'],\n",
       "       dtype='<U128'),\n",
       " array([\"were a roman; for i cannot,\\nbeing a volsce, be that i am. condition!\\nwhat good condition can a treaty find\\ni' the part that is a\",\n",
       "        'rowned head, the vigilant eye,\\nthe counsellor heart, the arm our soldier,\\nour steed the leg, the tongue our trumpeter.\\nwith othe',\n",
       "        'rtain number,\\nthough thanks to all, must i select\\nfrom all: the rest\\nshall bear the business in some other fight,\\nas cause will ',\n",
       "        \"me:\\nand welcome, general: and ye're welcome all.\\n\\nmenenius:\\na hundred thousand welcomes. i could weep\\nand i could laugh, i am li\",\n",
       "        \"ortunes\\nto hopeless restitution, so he might\\nbe call'd your vanquisher.\\n\\ncoriolanus:\\nat antium lives he?\\n\\nlartius:\\nat antium.\\n\\nc\",\n",
       "        \"us:\\ni'll keep you company. will you along?\\n\\nbrutus:\\nwe stay here for the people.\\n\\nsicinius:\\nfare you well.\\nhe has it now, and by\",\n",
       "        \"' the common, you shall find\\nno public benefit which you receive\\nbut it proceeds or comes from them to you\\nand no way from yours\",\n",
       "        \"t do it to the gods;\\nmust i then do't to them?\\n\\nvolumnia:\\nyou are too absolute;\\nthough therein you can never be too noble,\\nbut w\",\n",
       "        \"ratitude,\\nand tent themselves with death. of all the horses,\\nwhereof we have ta'en good and good store, of all\\nthe treasure in t\",\n",
       "        \"raves i' the holy churchyard.\\n\\ncoriolanus:\\nscratches with briers,\\nscars to move laughter only.\\n\\nmenenius:\\nconsider further,\\nthat\",\n",
       "        \"not without his\\ntrue purchasing.\\n\\nvirgilia:\\nthe gods grant them true!\\n\\nvolumnia:\\ntrue! pow, wow.\\n\\nmenenius:\\ntrue! i'll be sworn \",\n",
       "        \"bsolute power,\\ni say, they nourish'd disobedience, fed\\nthe ruin of the state.\\n\\nbrutus:\\nwhy, shall the people give\\none that speak\",\n",
       "        'placeth highest! so, farewell.\\n\\nlartius:\\nthou worthiest marcius!\\ngo, sound thy trumpet in the market-place;\\ncall thither all the',\n",
       "        \" death outweighs bad life\\nand that his country's dearer than himself;\\nlet him alone, or so many so minded,\\nwave thus, to express\",\n",
       "        \"inius:\\nwe charge you, that you have contrived to take\\nfrom rome all season'd office and to wind\\nyourself into a power tyrannical\",\n",
       "        'rt fort, but that he pays himself with being proud.\\n\\nsecond citizen:\\nnay, but speak not maliciously.\\n\\nfirst citizen:\\ni say unto ',\n",
       "        'erefore, beseech you,\\ni may be consul.\\n\\nfifth citizen:\\nwe hope to find you our friend; and therefore give\\nyou our voices heartil',\n",
       "        'th, look you, one cannot tell how to say that:\\nfor the defence of a town, our general is excellent.\\n\\nfirst servingman:\\nay, and f',\n",
       "        's with fins of lead\\nand hews down oaks with rushes. hang ye! trust ye?\\nwith every minute you do change a mind,\\nand call him nobl',\n",
       "        'm,\\ncannot conclude but by the yea and no\\nof general ignorance,--it must omit\\nreal necessities, and give way the while\\nto unstabl',\n",
       "        'find fame. to a cruel\\nwar i sent him; from whence he returned, his brows\\nbound with oak. i tell thee, daughter, i sprang not\\nmor',\n",
       "        \"senator:\\nnoble aufidius,\\ntake your commission; hie you to your bands:\\nlet us alone to guard corioli:\\nif they set down before 's,\",\n",
       "        \" loved\\nthe people.\\n\\nfirst citizen:\\nhe's one honest enough: would all the rest were so!\\n\\nmenenius:\\nwhat work's, my countrymen, in\",\n",
       "        '\\ni sin in envying his nobility,\\nand were i any thing but what i am,\\ni would wish me only he.\\n\\ncominius:\\nyou have fought together',\n",
       "        's: he hath resisted law,\\nand therefore law shall scorn him further trial\\nthan the severity of the public power\\nwhich he so sets ',\n",
       "        \"hat's a brave fellow; but he's vengeance proud, and\\nloves not the common people.\\n\\nsecond officer:\\nfaith, there had been many gre\",\n",
       "        \" people do with these bald tribunes?\\non whom depending, their obedience fails\\nto the greater bench: in a rebellion,\\nwhen what's \",\n",
       "        't to quench.\\n\\nfirst senator:\\nto unbuild the city and to lay all flat.\\n\\nsicinius:\\nwhat is the city but the people?\\n\\ncitizens:\\ntru',\n",
       "        \"i'll have you talked with anon.\\n\\nthird servingman:\\nwhat fellow's this?\\n\\nfirst servingman:\\na strange one as ever i looked on: i c\",\n",
       "        \"\\nmenenius:\\nthat's worthily\\nas any ear can hear. come, let's not weep.\\nif i could shake off but one seven years\\nfrom these old ar\",\n",
       "        'le confound an hour,\\nand bring thy news so late?\\n\\nmessenger:\\nspies of the volsces\\nheld me in chase, that i was forced to wheel\\nt',\n",
       "        \"id, the fittest time to corrupt a man's wife is\\nwhen she's fallen out with her husband. your noble\\ntullus aufidius will appear w\"],\n",
       "       dtype='<U128'))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba_ = model(X_batch)\n",
    "y_pred_ = tf.argmax(y_proba_, axis=2)  # choose the most probable character ID\n",
    "predicted_text = decoder(y_pred_)\n",
    "original_text = decoder(X_batch)\n",
    "predicted_text, original_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['e  nn o iie   ai    inn  ee   e o oe i e        o nnee  n   ieeiee        e o     nnne   ieeieiee  e  ie i ne iiie ii  een  ieie',\n",
       "       'oee a  oo ee   i ii  i  e e i inne nnno nnin i e i i    e   iiiei e   e  a a nee ieeee   nnnnn  iin i iie enee i iieei  ni i iei',\n",
       "       'ei  nneeeee  niiii nnn i ii n  ie ii   e i iiii i   i   ea i  oi i   e aoa   ioeeoe     i eie   i   e  i i  ie ani ianeineiniei ',\n",
       "       'ieeiiii  i i e ne o i a o  eeeeienineeeeneeeee  nnn ieeie       ee e   in i iee ie iiinneon         a e nn in iie  ieeeeeee i  e',\n",
       "       'iinn  iiie     ee   eaa i i i  i i  i  n oi i eae ii n iieieee    o   i  ineeeiiieeie a     ie ieeio nnen e   n  o   e o eeeee o',\n",
       "       'aeea    e   nnnn ie a  e o   iei i neiee  i i i  e e   ieii      ioonnn io   i n ni i  e  neeie a  oo ee   i ii  i  e e i inne n',\n",
       "       'i ii  ieei iii  eo   e i  nen nninn   e  eeei n i  ieee i  i  e oeo e  i  iiii e   n       n i   aa i  i  eii  eniii     ii ee e',\n",
       "       'oe i ii iieiee o e i    e  e i  eeieeinnnnene e   e  ne  nnnn nniee iiieie   eeiee  eeie iinien    innini ianenne   nnneeneei i ',\n",
       "       'eoan ne eie  e     o i i  ien ne  eii   eie i  eeni i   n  e i  nn ioneee i     ii e    e i    ee    eeeiee e   i ii ie    nnnnn',\n",
       "       'oe o  eiiiie iee   nnn  oeeee iieeeeeee  i eieiiei        onnoe iiinieeeniiiie e ieiiien i i  n  n  ii  eee   ne in n e  neiinni'],\n",
       "      dtype='<U128')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_proba_ = model(X_batch)\n",
    "# y_pred_ = tf.argmax(y_proba_, axis=-1)\n",
    "# decoder(y_pred_)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# y_pred_ = tf.argmax(y_proba_)  # choose the most probable character ID\n",
    "# len(decoder(y_pred_)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toydl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
