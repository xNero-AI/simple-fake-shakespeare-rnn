{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LET'S DO THISS!!! :DDDD\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Lets check your GPU\n",
    "if tf.config.list_logical_devices('GPU') != []:\n",
    "    print(\"LET'S DO THISS!!! :DDDD\")\n",
    "else: \n",
    "    print(\"Oh dude... D:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first citizen:\n",
      "before we proceed any further, hear me speak.\n",
      "\n",
      "all:\n",
      "speak, speak.\n",
      "\n",
      "first citizen:\n",
      "you\n"
     ]
    }
   ],
   "source": [
    "with open('data/input.txt') as f:\n",
    "    content = f.read().lower()\n",
    "    \n",
    "print(content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n !$&',-.3:;?abcdefghijklmnopqrstuvwxyz\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(sorted(set(content.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vec_layer = keras.layers.TextVectorization(\n",
    "                                                split=\"character\",\n",
    "                                                standardize=\"lower\"\n",
    "                                            )\n",
    "text_vec_layer.adapt([content])\n",
    "encoded = text_vec_layer([content])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded -= 2  # drop tokens 0 (pad) and 1 (unknown), subtraindo 2 (pad e unknown)\n",
    "n_tokens = text_vec_layer.vocabulary_size() - 2  # number of distinct chars = 39\n",
    "dataset_size = len(encoded)  # total number of chars = 1,115,394"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 1115394)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tokens, dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 128\n",
    "batch_size = 32\n",
    "ds = tf.data.Dataset.from_tensor_slices(encoded) # Fatia o ds em janelas de tamanho window_size\n",
    "ds = ds.window(window_size + 1, shift=1, drop_remainder=True) # Você pode visualizar com um .as_numpy_iterator() e colocar num loop com .take(1)\n",
    "ds = ds.flat_map(lambda window: window.batch(window_size + 1)) # Transforma cada janela em um tensor\n",
    "ds = ds.shuffle(100_000, seed=42)\n",
    "ds = ds.batch(batch_size)\n",
    "ds = ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128) (32, 128)\n",
      "tf.Tensor(\n",
      "[ 9 12  0 19  5 20  6  2  0 16  5  2  6  0  2 27  3  2  6  1  8 17 10  1\n",
      "  8  1  0  7  2  4 15  0 21  1  6  5  9 12  0  2  6  5  7  0 21 13  7  5\n",
      "  9  1  7  7 26 10 10 14  1  9  1  9  5 13  7 23 10  3 17  0  2  8 13  1\n",
      " 31 21  8  1 12 30 10 10 19  5  8  7  2  0  7  1  9  4  2  3  8 23 10 15\n",
      "  3 13  8  0 18  3 14 22  4  9 15  0  2  3  0  2  6  1  0 18  4 22  5  2\n",
      "  3 11 28  0 16  6  1  8], shape=(128,), dtype=int64) tf.Tensor(\n",
      "[12  0 19  5 20  6  2  0 16  5  2  6  0  2 27  3  2  6  1  8 17 10  1  8\n",
      "  1  0  7  2  4 15  0 21  1  6  5  9 12  0  2  6  5  7  0 21 13  7  5  9\n",
      "  1  7  7 26 10 10 14  1  9  1  9  5 13  7 23 10  3 17  0  2  8 13  1 31\n",
      " 21  8  1 12 30 10 10 19  5  8  7  2  0  7  1  9  4  2  3  8 23 10 15  3\n",
      " 13  8  0 18  3 14 22  4  9 15  0  2  3  0  2  6  1  0 18  4 22  5  2  3\n",
      " 11 28  0 16  6  1  8  1], shape=(128,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in ds.take(1):\n",
    "    print(X_batch.shape, y_batch.shape)\n",
    "    print(X_batch[0], y_batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando função\n",
    "def to_dataset(sequence, window_size=128, batch_size=32, seed=42, shuffle=False, target='all_window'):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(sequence) # Fatia o ds em janelas de tamanho window_size\n",
    "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True) # Você pode visualizar com um .as_numpy_iterator() e colocar num loop com .take(1)\n",
    "    ds = ds.flat_map(lambda window: window.batch(window_size + 1)) # Transforma cada janela em um tensor\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(100_000, seed=seed)\n",
    "    ds = ds.batch(batch_size)\n",
    "    if target == 'all_window':\n",
    "        ds = ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)\n",
    "    elif target == 'last_char':\n",
    "        ds = ds.map(lambda window: (window[:, :-1], window[:, -1])).prefetch(1)\n",
    "    else:\n",
    "        raise ValueError('target must be \"all_window\" or \"last_char\"')\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n",
       "  array([[ 4,  5,  2],\n",
       "         [ 5,  2, 23]], dtype=int64)>,\n",
       "  <tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n",
       "  array([[ 5,  2, 23],\n",
       "         [ 2, 23,  3]], dtype=int64)>)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo de uso\n",
    "list(to_dataset(text_vec_layer(['To be'])[0], window_size=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 128\n",
    "tf.random.set_seed(42)\n",
    "train_set = to_dataset(encoded[:1_000_000], window_size=window_size, shuffle=True, seed=42)\n",
    "valid_set = to_dataset(encoded[1_000_000:1_060_000], window_size=window_size)\n",
    "test_set = to_dataset(encoded[1_060_000:], window_size=window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Char-RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self, n_tokens):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.embedding = keras.layers.Embedding(input_dim=n_tokens, output_dim=16, input_shape=[None, 128])\n",
    "        self.conv1d = keras.layers.Conv1D(32, kernel_size=3, padding=\"causal\", activation=\"relu\")\n",
    "        self.gru = keras.layers.GRU(128, return_sequences=True)\n",
    "        # Adicionando uma camada de atenção\n",
    "        self.attention = keras.layers.Attention()\n",
    "        self.dense = keras.layers.Dense(n_tokens, activation=\"softmax\")\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.embedding(inputs)\n",
    "        x = self.conv1d(x)\n",
    "        x = self.gru(x)\n",
    "        # Aplicando atenção\n",
    "        # A camada de atenção precisa de duas entradas, neste caso, usamos `x` duas vezes.\n",
    "        x = self.attention([x, x])\n",
    "        x = self.dense(x)\n",
    "        return x\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)  # Forward pass\n",
    "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "# Configurando a seed para reprodutibilidade\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = CustomModel(n_tokens=n_tokens)\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"nadam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[15  0  9 ... 15 30 10]\n",
      " [25  1  0 ...  0  3 19]\n",
      " [13  7 23 ...  5  9  0]\n",
      " ...\n",
      " [25  1  0 ...  7 23 10]\n",
      " [11 12  0 ...  6  1  0]\n",
      " [ 1  0  5 ...  2  1  8]], shape=(32, 128), dtype=int64) tf.Tensor(\n",
      "[[ 0  9  3 ... 30 10 10]\n",
      " [ 1  0  3 ...  3 19  0]\n",
      " [ 7 23 10 ...  9  0  8]\n",
      " ...\n",
      " [ 1  0 21 ... 23 10 15]\n",
      " [12  0 15 ...  1  0  7]\n",
      " [ 0  5  2 ...  1  8 27]], shape=(32, 128), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in train_set.take(1):\n",
    "    print(X_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 128])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 128, 100), dtype=float32, numpy=\n",
       "array([[[0.00995005, 0.00998792, 0.00998975, ..., 0.00986534,\n",
       "         0.00993769, 0.0100949 ],\n",
       "        [0.00995005, 0.00998791, 0.00998975, ..., 0.00986535,\n",
       "         0.00993769, 0.01009491],\n",
       "        [0.00995005, 0.00998792, 0.00998974, ..., 0.00986535,\n",
       "         0.00993769, 0.01009492],\n",
       "        ...,\n",
       "        [0.00995005, 0.00998793, 0.00998975, ..., 0.00986534,\n",
       "         0.00993769, 0.0100949 ],\n",
       "        [0.00995004, 0.00998793, 0.00998976, ..., 0.00986534,\n",
       "         0.0099377 , 0.01009492],\n",
       "        [0.00995005, 0.00998793, 0.00998976, ..., 0.00986535,\n",
       "         0.0099377 , 0.01009492]],\n",
       "\n",
       "       [[0.00997565, 0.00998185, 0.00999155, ..., 0.00987234,\n",
       "         0.00994663, 0.01008519],\n",
       "        [0.00997565, 0.00998185, 0.00999155, ..., 0.00987237,\n",
       "         0.00994665, 0.01008518],\n",
       "        [0.00997566, 0.00998185, 0.00999155, ..., 0.00987235,\n",
       "         0.00994665, 0.01008518],\n",
       "        ...,\n",
       "        [0.00997564, 0.00998185, 0.00999154, ..., 0.00987235,\n",
       "         0.00994665, 0.01008518],\n",
       "        [0.00997565, 0.00998184, 0.00999154, ..., 0.00987235,\n",
       "         0.00994665, 0.01008518],\n",
       "        [0.00997564, 0.00998186, 0.00999153, ..., 0.00987236,\n",
       "         0.00994666, 0.01008518]],\n",
       "\n",
       "       [[0.00996623, 0.00998327, 0.00999319, ..., 0.00986839,\n",
       "         0.00993397, 0.01008706],\n",
       "        [0.00996622, 0.00998326, 0.00999319, ..., 0.00986842,\n",
       "         0.00993398, 0.01008706],\n",
       "        [0.00996622, 0.00998325, 0.00999321, ..., 0.0098684 ,\n",
       "         0.00993396, 0.01008707],\n",
       "        ...,\n",
       "        [0.00996623, 0.00998326, 0.00999319, ..., 0.00986841,\n",
       "         0.00993397, 0.01008706],\n",
       "        [0.00996623, 0.00998327, 0.00999319, ..., 0.00986841,\n",
       "         0.00993397, 0.01008707],\n",
       "        [0.00996622, 0.00998325, 0.0099932 , ..., 0.0098684 ,\n",
       "         0.00993396, 0.01008707]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.009975  , 0.00999457, 0.00998538, ..., 0.00986621,\n",
       "         0.00995147, 0.01010494],\n",
       "        [0.009975  , 0.00999457, 0.00998538, ..., 0.0098662 ,\n",
       "         0.00995147, 0.01010494],\n",
       "        [0.009975  , 0.00999456, 0.00998537, ..., 0.00986621,\n",
       "         0.00995147, 0.01010496],\n",
       "        ...,\n",
       "        [0.009975  , 0.00999455, 0.0099854 , ..., 0.00986621,\n",
       "         0.00995146, 0.01010493],\n",
       "        [0.00997501, 0.00999454, 0.0099854 , ..., 0.00986619,\n",
       "         0.00995145, 0.01010493],\n",
       "        [0.009975  , 0.00999454, 0.0099854 , ..., 0.0098662 ,\n",
       "         0.00995145, 0.01010492]],\n",
       "\n",
       "       [[0.00997373, 0.00998263, 0.00999222, ..., 0.0098619 ,\n",
       "         0.00994587, 0.01009464],\n",
       "        [0.00997374, 0.00998263, 0.00999223, ..., 0.0098619 ,\n",
       "         0.00994587, 0.01009464],\n",
       "        [0.00997374, 0.00998262, 0.00999224, ..., 0.00986189,\n",
       "         0.00994589, 0.01009465],\n",
       "        ...,\n",
       "        [0.00997372, 0.00998261, 0.00999222, ..., 0.00986189,\n",
       "         0.00994588, 0.01009467],\n",
       "        [0.00997372, 0.00998261, 0.00999223, ..., 0.00986188,\n",
       "         0.00994588, 0.01009467],\n",
       "        [0.00997373, 0.0099826 , 0.00999223, ..., 0.00986189,\n",
       "         0.00994587, 0.01009468]],\n",
       "\n",
       "       [[0.00996259, 0.00998328, 0.00999229, ..., 0.00986499,\n",
       "         0.00994053, 0.01009833],\n",
       "        [0.00996258, 0.00998326, 0.00999229, ..., 0.00986498,\n",
       "         0.00994053, 0.01009833],\n",
       "        [0.0099626 , 0.00998327, 0.00999229, ..., 0.00986499,\n",
       "         0.00994054, 0.01009833],\n",
       "        ...,\n",
       "        [0.0099626 , 0.00998328, 0.00999229, ..., 0.00986497,\n",
       "         0.00994053, 0.01009833],\n",
       "        [0.0099626 , 0.00998328, 0.00999229, ..., 0.00986497,\n",
       "         0.00994052, 0.01009832],\n",
       "        [0.00996259, 0.00998328, 0.00999231, ..., 0.00986497,\n",
       "         0.00994053, 0.01009833]]], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"custom_model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     multiple                  1600      \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           multiple                  1568      \n",
      "                                                                 \n",
      " gru_3 (GRU)                 multiple                  62208     \n",
      "                                                                 \n",
      " attention_3 (Attention)     multiple                  0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             multiple                  12900     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78,276\n",
      "Trainable params: 78,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estilo\n",
    "plt.style.use('dark_background')\n",
    "plt.rcParams['axes.facecolor'] = '#26262e' \n",
    "\n",
    "def print_multiple_generated(predicted_text, original_text, n=8):\n",
    "    print(\"--> Original text:\")\n",
    "    for i in range(n):\n",
    "        print(original_text[i])\n",
    "    print(\"\\n--> Generated text:\")\n",
    "    for i in range(n):\n",
    "        print(predicted_text[i])\n",
    "        \n",
    "def plot_loss(history, step):\n",
    "    plt.plot(list(range(len(history['loss']))), history['loss'], label='Training Loss')\n",
    "    plt.plot(list(range(len(history['loss']))), history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_accuracy(history, step):\n",
    "    plt.plot(list(range(len(history['accuracy']))), history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(list(range(len(history['accuracy']))), history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {\n",
    "            'text_base': 'To be or not ',\n",
    "            'text_base_encoded': text_vec_layer(['To be or not ']),\n",
    "            'list_predicted_text_base': [],\n",
    "        }\n",
    "\n",
    "class LogCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, history):\n",
    "        super().__init__()\n",
    "        self.history_ = history\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"Final da época {epoch}, Loss: {logs['loss']}, Acc: {logs['accuracy']}\")\n",
    "    \n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        if batch % 1_000 == 0:\n",
    "            print(\"\")\n",
    "            print(f\"Final do lote {batch}, Loss do lote: {logs['loss']}\")\n",
    "            model = self.model\n",
    "            # predicted_text = decoder(tf.argmax(model(history['text_base_encoded'], training=False), axis=2))[0]\n",
    "            predicted_text = extend_text(\"To be or not \", temperature=1.0)\n",
    "            print(\"\")\n",
    "            print(\"--> Original text: \", history['text_base'])\n",
    "            print(\"--> Generated text: \", predicted_text)\n",
    "            self.history_['list_predicted_text_base'].append(predicted_text)\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"my_shakespeare_custom_model_w_attention\", monitor=\"val_accuracy\", save_best_only=True)\n",
    "\n",
    "shakespeare_model = tf.keras.Sequential([\n",
    "    text_vec_layer,\n",
    "    tf.keras.layers.Lambda(lambda X: X - 2),  # no <PAD> or <UNK> tokens\n",
    "    model\n",
    "])\n",
    "\n",
    "tf.random.set_seed(42)  # extra code – ensures reproducibility on CPU\n",
    "\n",
    "def next_char(text, temperature=1):\n",
    "    y_proba = shakespeare_model.predict([text], verbose=0)[0, -1:]\n",
    "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1)[0, 0]\n",
    "    print(char_id)\n",
    "    return text_vec_layer.get_vocabulary()[char_id]\n",
    "\n",
    "def extend_text(text, n_chars=50, temperature=1):\n",
    "    for _ in range(n_chars):\n",
    "        text += next_char(text, temperature)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_vec_layer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\n",
      "Final do lote 0, Loss do lote: 4.591318130493164\n",
      "tf.Tensor(52, shape=(), dtype=int64)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history_train \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mLogCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mmodel_ckpt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\toydl\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[36], line 21\u001b[0m, in \u001b[0;36mLogCallback.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m     19\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# predicted_text = decoder(tf.argmax(model(history['text_base_encoded'], training=False), axis=2))[0]\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m predicted_text \u001b[38;5;241m=\u001b[39m \u001b[43mextend_text\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTo be or not \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--> Original text: \u001b[39m\u001b[38;5;124m\"\u001b[39m, history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_base\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[1;32mIn[44], line 21\u001b[0m, in \u001b[0;36mextend_text\u001b[1;34m(text, n_chars, temperature)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextend_text\u001b[39m(text, n_chars\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_chars):\n\u001b[1;32m---> 21\u001b[0m         text \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mnext_char\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "Cell \u001b[1;32mIn[44], line 17\u001b[0m, in \u001b[0;36mnext_char\u001b[1;34m(text, temperature)\u001b[0m\n\u001b[0;32m     15\u001b[0m char_id \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mcategorical(rescaled_logits, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(char_id)\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtext_vec_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_vocabulary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchar_id\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "history_train = model.fit(train_set, \n",
    "                    validation_data=valid_set, \n",
    "                    epochs=10,\n",
    "                    callbacks=[LogCallback(history=history), \n",
    "                               model_ckpt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toydl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
